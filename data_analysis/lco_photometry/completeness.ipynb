{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "778de581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from astropy.io import ascii"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e6ceb2",
   "metadata": {},
   "source": [
    "## Data (after running `twirler.py` on the g', r', i' and processing all them+J/C filters in AIJ)\n",
    "\n",
    "### Note, in the `*_badfiles` objects we remove a subset of images from each output-AIJ light curve. See Sec. 2.1.1 in Schochet & Feinstein (in prep) for an explanation of why this was necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b67bc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gp\n",
    "# ---\n",
    "gp_data = ascii.read('/Users/mschochet/Desktop/MSU_PHD/lco_aumic/lcs_posttwirl/gp.xls')\n",
    "gp_data.sort(keys='rel_flux_T1')\n",
    "gp_badfiles = [str(val) for val in list(gp_data[:2]['Label'])]\n",
    "\n",
    "gp_cleaned = gp_data[2:] # Remove any frames where AIJ misplaced the aperture and T1 or C2 fluxes are negative/near-0\n",
    "gp_cleaned.sort(keys='J.D.-2400000')\n",
    "gp_d, gp_aum_flux, gp_c1_flux = gp_cleaned['J.D.-2400000'], gp_cleaned['rel_flux_T1'], gp_cleaned['rel_flux_C2']\n",
    "# ---\n",
    "\n",
    "#ip\n",
    "# ---\n",
    "ip_data = ascii.read('/Users/mschochet/Desktop/MSU_PHD/lco_aumic/lcs_posttwirl/ip.xls')\n",
    "ip_data.sort(keys='rel_flux_T1')\n",
    "ip_badfiles = [str(val) for val in list(ip_data[:28]['Label'])]\n",
    "ip_badfiles.append(ip_data[len(ip_data)-1][\"Label\"])\n",
    "\n",
    "ip_cleaned = ip_data[28:len(ip_data)-1] # Same as above but there is a +40 value out of nowhere, don't think that is real\n",
    "ip_cleaned.sort(keys='J.D.-2400000')\n",
    "ip_d, ip_aum_flux, ip_c1_flux = ip_cleaned['J.D.-2400000'], ip_cleaned['rel_flux_T1'], ip_cleaned['rel_flux_C2']\n",
    "# ---\n",
    "#rp\n",
    "# ---\n",
    "rp_data = ascii.read('/Users/mschochet/Desktop/MSU_PHD/lco_aumic/lcs_posttwirl/rp.xls')\n",
    "rp_data.sort(keys='rel_flux_T1')\n",
    "rp_badfiles = [str(val) for val in list(rp_data[:1]['Label'])]\n",
    "\n",
    "rp_cleaned = rp_data[1:] # Same as above but there is only one bad value\n",
    "rp_cleaned.sort(keys='J.D.-2400000')\n",
    "rp_d, rp_aum_flux, rp_c1_flux = rp_cleaned['J.D.-2400000'], rp_cleaned['rel_flux_T1'], rp_cleaned['rel_flux_C2']\n",
    "# ---\n",
    "#U\n",
    "# ---\n",
    "U_data = ascii.read('/Users/mschochet/Desktop/MSU_PHD/lco_aumic/lcs_posttwirl/U.xls')\n",
    "U_data.sort(keys='rel_flux_T1')\n",
    "U_badfiles = [str(val) for val in list(U_data[(len(U_data))-13:]['Label'])]\n",
    "U_badfiles.append(U_data[0][\"Label\"])\n",
    "U_badfiles.append(U_data[1][\"Label\"])\n",
    "\n",
    "\n",
    "U_cleaned = U_data[2:(len(U_data))-13]# Same as above but there are 13 values with substantially too large flux values, and 2 with values too low \n",
    "U_cleaned.sort(keys='J.D.-2400000')\n",
    "U_d, U_aum_flux, U_c1_flux = U_cleaned['J.D.-2400000'], U_cleaned['rel_flux_T1'], U_cleaned['rel_flux_C2']\n",
    "# ---\n",
    "#B\n",
    "# ---\n",
    "B_data = ascii.read('/Users/mschochet/Desktop/MSU_PHD/lco_aumic/lcs_posttwirl/B.xls')\n",
    "\n",
    "B_cleaned = B_data.copy()\n",
    "B_cleaned.sort(keys='J.D.-2400000')\n",
    "B_d, B_aum_flux, B_c1_flux = B_cleaned['J.D.-2400000'], B_cleaned['rel_flux_T1'], B_cleaned['rel_flux_C2']\n",
    "# ---\n",
    "#V\n",
    "# ---\n",
    "V_data = ascii.read('/Users/mschochet/Desktop/MSU_PHD/lco_aumic/lcs_posttwirl/V.xls')\n",
    "\n",
    "V_cleaned = V_data.copy()\n",
    "V_cleaned.sort(keys='J.D.-2400000')\n",
    "V_d, V_aum_flux, V_c1_flux = V_cleaned['J.D.-2400000'], V_cleaned['rel_flux_T1'], V_cleaned['rel_flux_C2']\n",
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bfb21c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete(og_num, current):\n",
    "    return (len(current)*100/og_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6763ed26",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_gp, og_ip, og_rp, og_U, og_B, og_V = 494, 500, 483, 414, 125, 141\n",
    "list_ognums = [og_U, og_B, og_V, og_gp, og_rp, og_ip]\n",
    "lengths = [U_cleaned, B_cleaned, V_cleaned, gp_cleaned, rp_cleaned, ip_cleaned]\n",
    "\n",
    "completenesses = [complete(og_num, length) for og_num,length in zip(list_ognums, lengths)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31991f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The completeness of our processed light curve in the U filter is: 83.82%\n",
      "The completeness of our processed light curve in the B filter is: 100.00%\n",
      "The completeness of our processed light curve in the V filter is: 100.00%\n",
      "The completeness of our processed light curve in the g' filter is: 97.17%\n",
      "The completeness of our processed light curve in the i' filter is: 97.31%\n",
      "The completeness of our processed light curve in the r' filter is: 85.80%\n"
     ]
    }
   ],
   "source": [
    "for complete, filter in zip(completenesses, ['U', 'B', 'V','g\\'', 'i\\'', 'r\\'']):\n",
    "    print('The completeness of our processed light curve in the', filter, 'filter is:', f\"{complete:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
